{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6bdf34-8665-432b-a944-13ebe977aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/cmusfel1/.cache/huggingface\n",
      "/scratch/cmusfel1/.cache/huggingface/datasets\n",
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## set up configs for huggingface hub and OS paths on HPC cluster -- make sure config.ini is correct\n",
    "## ---------------------------------------------------------------------\n",
    "import configparser\n",
    "def auth_token():\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return config[\"hugging_face\"][\"token\"]\n",
    "\n",
    "def scratch_path():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return \"/scratch/\" + config[\"user\"][\"username\"] + \"/\"\n",
    "\n",
    "import os\n",
    "if os.path.isdir(scratch_path()):\n",
    "    os.environ['TRANSFORMERS_CACHE'] = scratch_path() + '.cache/huggingface'\n",
    "    os.environ['HF_DATASETS_CACHE'] = scratch_path() + '.cache/huggingface/datasets'\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n",
    "print(os.getenv('HF_DATASETS_CACHE'))\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Load libraries\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Ensure GPU is available -- device should == 'cuda'\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68833b8a-c4f5-48dd-8153-2c7ad99b7f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0043985843658447266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c9ff087c08447db7ba3fad14e8e130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## load llama-2 and set up a pipeline\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model = MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    use_auth_token = auth_token()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fde841-b59e-4675-95ca-bd83bc1367cc",
   "metadata": {},
   "source": [
    "<h2>answer_questions() function</h2>\n",
    "<p>This function will read a multiple choice question from the dataset and output a single letter response.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3f098e-cb23-49f8-9ee4-7ea3056e96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/cmusfel1/test.tsv\", sep='\\t')\n",
    "data2 = data.copy().tail(10) #smaller df for testing\n",
    "\n",
    "with open(\"/home/cmusfel1/prompt1.txt\", 'r') as file:\n",
    "    answer_prompt = file.read()\n",
    "\n",
    "def answer_questions(question, model, tokenizer):\n",
    "    input_str = answer_prompt + f\"\\nQuestion: {question}\\nAnswer:\"\n",
    "    #print(input_str)\n",
    "    sequences = model(\n",
    "        input_str,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=1,\n",
    "    )\n",
    "    \n",
    "    answer = sequences[0]['generated_text'][-1]\n",
    "    #print(answer)\n",
    "    return answer\n",
    "\n",
    "data2.loc[:, 'Model Answer'] = data2.apply(\n",
    "    lambda row: answer_questions(row['Complete Question'], pipeline, tokenizer),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacf2e1-629c-454a-a425-b5f2c07c91e7",
   "metadata": {},
   "source": [
    "<h2>generate_statement() function</h2>\n",
    "<p>This function will read the multiple choice question and the model's answer from the dataset and output a statement.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bfb2747-d73c-4577-83d7-cd827f2db0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/grp_dmpowell/.mamba/envs/EasyEditShared/lib/python3.9/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/cmusfel1/prompt2.txt\", 'r') as file:\n",
    "    statement_prompt = file.read()\n",
    "    \n",
    "def generate_statement(question, answer, model, tokenizer):\n",
    "    input_str = f\"\\n{statement_prompt}\\nQuestion: {question}\\nAnswer: {answer}\\nStatement:\"\n",
    "    #print(input_str)\n",
    "    sequences = model(\n",
    "        input_str,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        max_new_tokens=80,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=tokenizer.eos_token_id \n",
    "    )\n",
    "    \n",
    "    generated_text = sequences[0]['generated_text']\n",
    "    #print(generated_text)\n",
    "    statement = generated_text.split('Statement:')[5].split('*')[0] #added '*' direction in prompt2.txt to help with post processing\n",
    "    #print(statement)\n",
    "    return statement\n",
    "\n",
    "data2.loc[:, 'Generated Statement'] = data2.apply(\n",
    "    lambda row: generate_statement(row['Complete Question'], row['Model Answer'], pipeline, tokenizer),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e2e8c-053d-4f9a-8e1d-3f125b4dc5ac",
   "metadata": {},
   "source": [
    "<h2>generate_premises() function</h2>\n",
    "<p>This function will read the model's statement from the data set and provide two premises that would make the statement true.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db215361-322c-42e9-a759-2ceb1c6d64c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/grp_dmpowell/.mamba/envs/EasyEditShared/lib/python3.9/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/cmusfel1/prompt3.txt\", 'r') as file:\n",
    "    premises_prompt = file.read()\n",
    "    \n",
    "def generate_premises(statement, model, tokenizer):\n",
    "    input_str = f\"\\n{premises_prompt}\\nStatement: {statement}\\nPremises:\"\n",
    "    #print(input_str)\n",
    "    sequences = model(\n",
    "        input_str,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        max_new_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    generated_text = sequences[0]['generated_text']\n",
    "    #print(generated_text)\n",
    "    premises = generated_text.split('Premises:')[5].split('\\n')[0] #post processing\n",
    "    #print(premises)\n",
    "    return premises\n",
    "\n",
    "data2.loc[:, 'Generated Premises'] = data2.apply(\n",
    "    lambda row: generate_premises(row['Generated Statement'], pipeline, tokenizer),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26220e3-c719-4eb9-8c70-cd8eb99ac18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question Stem</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Complete Question</th>\n",
       "      <th>Answer Key</th>\n",
       "      <th>Model Answer</th>\n",
       "      <th>Generated Statement</th>\n",
       "      <th>Generated Premises</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>9-743</td>\n",
       "      <td>where might a bunny live?</td>\n",
       "      <td>(A) a thicket (B) atop palm trees (C) a sewer ...</td>\n",
       "      <td>where might a bunny live? (A) a thicket (B) at...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>where might a bunny live?</td>\n",
       "      <td>(1) Bunnies prefer to live in the country. (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>9-645</td>\n",
       "      <td>A shark will be unable to survive on eating al...</td>\n",
       "      <td>(A) it is a predator (B) it is a vegetarian (C...</td>\n",
       "      <td>A shark will be unable to survive on eating al...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A shark will be unable to survive on eating a...</td>\n",
       "      <td>(1) Sharks are predators. (2) Moss and algae ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>8-250</td>\n",
       "      <td>A meadow vole just gave birth, and needs to fe...</td>\n",
       "      <td>(A) oil (B) deer (C) bugs (D) recycled plastic...</td>\n",
       "      <td>A meadow vole just gave birth, and needs to fe...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A meadow vole just gave birth, and needs to f...</td>\n",
       "      <td>(1) A meadow vole eats bugs. (2) A meadow vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>283</td>\n",
       "      <td>The Grand Canyon was formed by</td>\n",
       "      <td>(A) a volcano erupting in 1782 (B) a river nam...</td>\n",
       "      <td>The Grand Canyon was formed by (A) a volcano e...</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>The Grand Canyon was formed by a river named ...</td>\n",
       "      <td>(1) Rivers can cause valleys and canyons to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>8-183</td>\n",
       "      <td>A woman, with a pale complexion, wants to spen...</td>\n",
       "      <td>(A) UV rays are harmful (B) sunlight will be f...</td>\n",
       "      <td>A woman, with a pale complexion, wants to spen...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A woman, with a pale complexion, wants to spe...</td>\n",
       "      <td>(1) Sunscreen is used to protect skin from UV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>9-284</td>\n",
       "      <td>A person is heating water in order to cook pas...</td>\n",
       "      <td>(A) scalds (B) cools (C) toasts (D) freezes</td>\n",
       "      <td>A person is heating water in order to cook pas...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A person is heating water in order to cook pa...</td>\n",
       "      <td>(1) A rock dropped in a pond creates a rippli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>7-1186</td>\n",
       "      <td>Pasta may be cooked in water when</td>\n",
       "      <td>(A) the water is warm (B) the water is on the ...</td>\n",
       "      <td>Pasta may be cooked in water when (A) the wate...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>Pasta may be cooked in water when the water i...</td>\n",
       "      <td>(1) Pasta is cooked in water (2) Water can be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>926</td>\n",
       "      <td>A decrease in diseases</td>\n",
       "      <td>(A) has no impact on a population (B) leads to...</td>\n",
       "      <td>A decrease in diseases (A) has no impact on a ...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A decrease in diseases leads to less sick peo...</td>\n",
       "      <td>(1) Diseases are the main cause of illness. (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7-519</td>\n",
       "      <td>When soil is viewed in a scientific way, what ...</td>\n",
       "      <td>(A) insects like big beetles (B) tiny lifeform...</td>\n",
       "      <td>When soil is viewed in a scientific way, what ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>When soil is viewed in a scientific way, what...</td>\n",
       "      <td>(1) Soil is made up of tiny lifeforms. (2) Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>7-7</td>\n",
       "      <td>Some animals use a liquid coming from their sk...</td>\n",
       "      <td>(A) cold (B) water (C) heat (D) humidity</td>\n",
       "      <td>Some animals use a liquid coming from their sk...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Some animals use a liquid coming from their s...</td>\n",
       "      <td>(1) Animals with glands, such as porcupines, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                      Question Stem  \\\n",
       "490   9-743                          where might a bunny live?   \n",
       "491   9-645  A shark will be unable to survive on eating al...   \n",
       "492   8-250  A meadow vole just gave birth, and needs to fe...   \n",
       "493     283                     The Grand Canyon was formed by   \n",
       "494   8-183  A woman, with a pale complexion, wants to spen...   \n",
       "495   9-284  A person is heating water in order to cook pas...   \n",
       "496  7-1186                  Pasta may be cooked in water when   \n",
       "497     926                             A decrease in diseases   \n",
       "498   7-519  When soil is viewed in a scientific way, what ...   \n",
       "499     7-7  Some animals use a liquid coming from their sk...   \n",
       "\n",
       "                                               Choices  \\\n",
       "490  (A) a thicket (B) atop palm trees (C) a sewer ...   \n",
       "491  (A) it is a predator (B) it is a vegetarian (C...   \n",
       "492  (A) oil (B) deer (C) bugs (D) recycled plastic...   \n",
       "493  (A) a volcano erupting in 1782 (B) a river nam...   \n",
       "494  (A) UV rays are harmful (B) sunlight will be f...   \n",
       "495        (A) scalds (B) cools (C) toasts (D) freezes   \n",
       "496  (A) the water is warm (B) the water is on the ...   \n",
       "497  (A) has no impact on a population (B) leads to...   \n",
       "498  (A) insects like big beetles (B) tiny lifeform...   \n",
       "499           (A) cold (B) water (C) heat (D) humidity   \n",
       "\n",
       "                                     Complete Question Answer Key  \\\n",
       "490  where might a bunny live? (A) a thicket (B) at...          A   \n",
       "491  A shark will be unable to survive on eating al...          A   \n",
       "492  A meadow vole just gave birth, and needs to fe...          C   \n",
       "493  The Grand Canyon was formed by (A) a volcano e...          C   \n",
       "494  A woman, with a pale complexion, wants to spen...          A   \n",
       "495  A person is heating water in order to cook pas...          A   \n",
       "496  Pasta may be cooked in water when (A) the wate...          C   \n",
       "497  A decrease in diseases (A) has no impact on a ...          C   \n",
       "498  When soil is viewed in a scientific way, what ...          B   \n",
       "499  Some animals use a liquid coming from their sk...          C   \n",
       "\n",
       "    Model Answer                                Generated Statement  \\\n",
       "490            A                         where might a bunny live?    \n",
       "491            A   A shark will be unable to survive on eating a...   \n",
       "492            C   A meadow vole just gave birth, and needs to f...   \n",
       "493            B   The Grand Canyon was formed by a river named ...   \n",
       "494            A   A woman, with a pale complexion, wants to spe...   \n",
       "495            A   A person is heating water in order to cook pa...   \n",
       "496            A   Pasta may be cooked in water when the water i...   \n",
       "497            C   A decrease in diseases leads to less sick peo...   \n",
       "498            B   When soil is viewed in a scientific way, what...   \n",
       "499            C   Some animals use a liquid coming from their s...   \n",
       "\n",
       "                                    Generated Premises  \n",
       "490   (1) Bunnies prefer to live in the country. (2...  \n",
       "491   (1) Sharks are predators. (2) Moss and algae ...  \n",
       "492   (1) A meadow vole eats bugs. (2) A meadow vol...  \n",
       "493   (1) Rivers can cause valleys and canyons to f...  \n",
       "494   (1) Sunscreen is used to protect skin from UV...  \n",
       "495   (1) A rock dropped in a pond creates a rippli...  \n",
       "496   (1) Pasta is cooked in water (2) Water can be...  \n",
       "497   (1) Diseases are the main cause of illness. (...  \n",
       "498   (1) Soil is made up of tiny lifeforms. (2) Th...  \n",
       "499   (1) Animals with glands, such as porcupines, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506dd659-757a-4951-b84d-34cee638cf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "easyedit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
