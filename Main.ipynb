{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6bdf34-8665-432b-a944-13ebe977aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/dmpowell/.cache/huggingface\n",
      "/scratch/dmpowell/.cache/huggingface/datasets\n",
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## set up configs for huggingface hub and OS paths on HPC cluster -- make sure config.ini is correct\n",
    "## ---------------------------------------------------------------------\n",
    "import configparser\n",
    "def auth_token():\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return config[\"hugging_face\"][\"token\"]\n",
    "\n",
    "def scratch_path():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return \"/scratch/\" + config[\"user\"][\"username\"] + \"/\"\n",
    "\n",
    "import os\n",
    "if os.path.isdir(scratch_path()):\n",
    "    os.environ['TRANSFORMERS_CACHE'] = scratch_path() + '.cache/huggingface'\n",
    "    os.environ['HF_DATASETS_CACHE'] = scratch_path() + '.cache/huggingface/datasets'\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n",
    "print(os.getenv('HF_DATASETS_CACHE'))\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Load libraries\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Ensure GPU is available -- device should == 'cuda'\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68833b8a-c4f5-48dd-8153-2c7ad99b7f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00457310676574707,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 73,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74def3763247420fa4dceedbe2356ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## load llama-2 and set up a pipeline\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model = MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    use_auth_token = auth_token()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "64a29eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.tsv\", sep='\\t')\n",
    "df2 = df.copy().tail(10) # smaller df for testing\n",
    "\n",
    "with open(\"prompt1.txt\", 'r') as file:\n",
    "    answer_prompt = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fde841-b59e-4675-95ca-bd83bc1367cc",
   "metadata": {},
   "source": [
    "<h2>answer_questions() function</h2>\n",
    "<p>This function will read a multiple choice question from the dataset and output a single letter response.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e67cb047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: A person wants to start saving money so that they can afford a nice vacation at the end of the year. After looking over their budget and expenses, they decide the best way to save money is to (A) make more phone calls (B) quit eating lunch out (C) buy less with monopoly money (D) have lunch with friends\n",
      "Answer: B\n",
      "Question: There is most likely going to be fog around: (A) a marsh (B) a tundra (C) the plains (D) a desert\n",
      "Answer: A\n",
      "Question: Predators eat (A) lions (B) humans (C) bunnies (D) grass\n",
      "Answer: C\n",
      "Question: Oak tree seeds are planted and a sidewalk is paved right next to that spot, until eventually, the tree is tall and the roots must extend past the sidewalk, which means (A) roots may be split (B) roots may begin to die (C) parts may break the concrete (D) roots may fall apart\n",
      "Answer: C\n",
      "Question: An electric car runs on electricity via (A) gasoline (B) a power station (C) electrical conductors (D) fuel\n",
      "Answer: C\n",
      "Question: As the rain forest is deforested the atmosphere will increase with (A) oxygen (B) nitrogen (C) carbon (D) rain\n",
      "Answer: C\n",
      "Question: an electric car contains a motor that runs on (A) gas (B) hydrogen (C) ions (D) plutonium\n",
      "Answer: C\n",
      "Question: The middle of the day usually involves the bright star nearest to the earth to be straight overhead why? (A) moons gravity (B) human planet rotation (C) global warming (D) moon rotation\n",
      "Answer: B\n",
      "Question: The summer solstice in the northern hemisphere is four months before (A) May (B) July (C) April (D) October\n",
      "Answer: D\n",
      "Question: The main component in dirt is (A) microorganisms (B) broken stones (C) pollution (D) bacteria\n",
      "Answer: B\n",
      "Question: It's easier for human's to survive in: (A) a cave (B) the ocean. (C) a town (D) alone\n",
      "Answer: C\n",
      "Question: A cactus stem is used to store (A) fruit (B) liquid (C) food (D) spines\n",
      "Answer: B\n",
      "Question: A red-tailed hawk is searching for prey. It is most likely to swoop down on (A) an eagle (B) a cow (C) a gecko (D) a deer\n",
      "Answer: C\n",
      "Question: The chance of wildfires is increased by (A) parched foliage (B) torrential rain (C) lush foliage (D) careful fire maintenance\n",
      "Answer: A\n",
      "Question: A positive effect of burning biofuel is (A) shortage of crops for the food supply (B) an increase in air pollution (C) powering the lights in a home (D) deforestation in the amazon to make room for crops\n",
      "Answer: C\n",
      "Question: As gasoline costs rise, alternative fuels are being used, which means that (A) wind power will be expensive (B) gas costs will rise (C) oil costs will be maintained (D) gasoline will be needed less\n",
      "Answer: D\n",
      "Question: A person wants to be able to have more natural power in their home. They choose to cease using a traditional electric company to source this electricity, and so decide to install (A) sun grafts (B) sunlight shields (C) panels collecting sunlight (D) solar bees\n",
      "Answer: C\n",
      "Question: A Mola Mola might live where? (A) Lake Michigan (B) The Mississippi River (C) Bay of Bengal (D) Lake Eerie\n",
      "Answer: C\n",
      "Question: Which requires energy to move? (A) weasel (B) willow (C) mango (D) poison ivy\n",
      "Answer: A\n",
      "Question: An animal that only eats plants is a (A) rat (B) moth (C) chimpanzee (D) pig\n",
      "Answer: B\n",
      "Question: There was a lot more water vapor in the air when we went on a trip to (A) Hanoi (B) Athens (C) Baghdad (D) Phoenix\n",
      "Answer: A\n",
      "Question: An example of conservation is avoiding the use of (A) gasoline (B) air (C) snow (D) clothes\n",
      "Answer: A\n",
      "Question: What can feathers on Spheniscidae be used for? (A) keeping warm (B) flying (C) sleeping (D) eating\n",
      "Answer: A\n",
      "Question: Overpopulation can cause (A) More fresh water for people to drink (B) Lower Life Expectancy in Countries (C) More food for more people (D) More space for places to people to live\n",
      "Answer: B\n",
      "Question: Shining a light through a diamond can (A) make a lot of bright lights shine (B) summon a brilliant wave of color (C) heat up a room (D) make a lot of money\n",
      "Answer: B\n",
      "Question: If you were attacked by a shark and had to punch it sharply where it pulls in air from, you'd use your hand to make contact with (A) its snout (B) its gills (C) its nose (D) its belly\n",
      "Answer: B\n",
      "Question: which of these would stop a car quicker? (A) a wheel with wet brake pads (B) a wheel without brake pads (C) a wheel with worn brake pads (D) a wheel with dry brake pads\n",
      "Answer: D\n",
      "Question: what system is needed for a body to get its needed supply of the gas humans breathe in? (A) the circulatory system (B) the digestive system (C) the school system (D) central nervous system\n",
      "Answer: A\n",
      "Question: Every evening a child can look into the night sky and see that the moon is (A) gone (B) breaking (C) falling (D) moving upwards\n",
      "Answer: D\n",
      "Question: When it's flying, a plane has no friction with the (A) wings (B) ground (C) air (D) clouds\n",
      "Answer: B\n",
      "Question: To grow plants require (A) acid rain (B) pesticides (C) shafts of sunlight (D) moonbeam rays\n",
      "Answer: C\n",
      "Question: What is the best way to guess a babies eye color? (A) The surroundings they are born in. (B) Their parents usual diet. (C) Just take a random guess. (D) The genealogy records of their family.\n",
      "Answer: D\n",
      "Question: What animal eats plants? (A) eagles (B) robins (C) owls (D) leopards\n",
      "Answer: B\n",
      "Question: Which of these is a hypothesis? (A) The ice caps will completely melt if global warming continues (B) The earth is round (C) The earth revolves around the sun (D) Gravity causes objects to fall\n",
      "Answer: A\n",
      "Question: What explains the characteristic lunar formations? (A) remains of ancient ponds (B) many collisions that have occured (C) volcanic explosions over millions of years (D) sink holes due to the moons porous nature\n",
      "Answer: B\n",
      "Question: Tadpoles start their lives as (A) Water animals (B) Frogs (C) Ants (D) College Students\n",
      "Answer: A\n",
      "Question: If a person puts out four apples around their home on the same day, the molecules in which apple would be moving the most rapidly? (A) the apple sitting on a sunny sidewalk (B) the apple in the freezer (C) the apple sitting on the shaded stoop (D) the apple in a closet\n",
      "Answer: A\n",
      "Question: What is used for sensing visual things? (A) nerves (B) tibia (C) nostril (D) cornea\n",
      "Answer: D\n",
      "Question: They studied the soil by using (A) plants (B) a telescope (C) roots (D) a microscope\n",
      "Answer: D\n",
      "Question: Bill's arm got cold when he put it inside the (A) refrigerator (B) room (C) jacket (D) oven\n",
      "Answer: A\n"
     ]
    }
   ],
   "source": [
    "plist = []\n",
    "for i in range(40):\n",
    "    plist.append(\"Question: \" + df.iloc[i][\"Complete Question\"] + \"\\nAnswer: \" + df.iloc[i][\"Answer Key\"])\n",
    "\n",
    "answer_prompt = \"\\n\".join(plist)\n",
    "print(answer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7f3f098e-cb23-49f8-9ee4-7ea3056e96dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/grp_dmpowell/.mamba/envs/EasyEditShared/lib/python3.9/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def answer_questions(question, model, tokenizer):\n",
    "    input_str = answer_prompt + f\"\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "    sequences = model(\n",
    "        input_str,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=1,\n",
    "    )\n",
    "    \n",
    "    answer = sequences[0]['generated_text'][-1]\n",
    "    #print(answer)\n",
    "    return answer\n",
    "\n",
    "df2['Model Answer'] = df2.apply(\n",
    "    lambda row: answer_questions(row['Complete Question'], pipeline, tokenizer),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e4cc6000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df2[\"Answer Key\"] == df2[\"Model Answer\"]) # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72891a",
   "metadata": {},
   "source": [
    "This is getting ~58% accuracy. For reference, the original GPT-3 with 32-shot examples got 65.8% ([Brown et al., 2020](https://arxiv.org/abs/2005.14165v4)). So that seems not-too-bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacf2e1-629c-454a-a425-b5f2c07c91e7",
   "metadata": {},
   "source": [
    "### ~~generate_statement() function~~\n",
    "~~This function will read the multiple choice question and the model's answer from the dataset and output a statement.~~\n",
    "\n",
    "**This ends up not being needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1bfb2747-d73c-4577-83d7-cd827f2db0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/grp_dmpowell/.mamba/envs/EasyEditShared/lib/python3.9/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"prompt2.txt\", 'r') as file:\n",
    "    statement_prompt = file.read()\n",
    "    \n",
    "def generate_statement(question, answer, model, tokenizer):\n",
    "    input_str = f\"{statement_prompt}\\n\\nQuestion: {question}\\nAnswer: {answer}\\nStatement:\"\n",
    "    #print(input_str)\n",
    "    sequences = model(\n",
    "        input_str,\n",
    "        do_sample=True,\n",
    "        top_k=5,\n",
    "        max_new_tokens=80,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=tokenizer.eos_token_id \n",
    "    )\n",
    "    \n",
    "    generated_text = sequences[0]['generated_text']\n",
    "    statement = generated_text[len(input_str):-1] #added '*' direction in prompt2.txt to help with post processing\n",
    "    \n",
    "    return statement.split(\".\")[0]\n",
    "\n",
    "\n",
    "# print(generate_statement(df2.iloc[1][\"Complete Question\"], df2.iloc[1][\"Model Answer\"], pipeline, tokenizer))\n",
    "df2['Generated Statement'] = df2.apply(\n",
    "    lambda row: generate_statement(row['Complete Question'], row['Model Answer'], pipeline, tokenizer),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e2e8c-053d-4f9a-8e1d-3f125b4dc5ac",
   "metadata": {},
   "source": [
    "## generate_premises() function\n",
    "~~This function will read the model's statement from the data set and provide two premises that would make the statement true.~~\n",
    "\n",
    "UPDATE: This seems to work better if we include the original question and answer, which eliminates a point of failure and gives more context for the explanation / premise generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "db215361-322c-42e9-a759-2ceb1c6d64c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/grp_dmpowell/.mamba/envs/EasyEditShared/lib/python3.9/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"prompt3b.txt\", 'r') as file:\n",
    "    premises_prompt = file.read()\n",
    "    \n",
    "def generate_premises(question, answer, model, tokenizer):\n",
    "    input_str = f\"\\n\\n{premises_prompt}Question: {question}\\nAnswer: {answer}\\n\"\n",
    "    #print(input_str)\n",
    "    sequences = model(\n",
    "        input_str,\n",
    "        # do_sample=True,\n",
    "        # top_k = 50, \n",
    "        num_beams = 5, # beam search may be better ...\n",
    "        max_new_tokens=150,\n",
    "        temperature = 0.7\n",
    "    )\n",
    "    \n",
    "    generated_text = sequences[0]['generated_text']\n",
    "    premises = generated_text[len(input_str):-1] \n",
    "    return premises.split(\"\\n\")[:2]\n",
    "\n",
    "df2['Generated Premises'] = df2.apply(\n",
    "    lambda row: generate_premises(row['Complete Question'], row['Answer Key'], pipeline, tokenizer),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e26220e3-c719-4eb9-8c70-cd8eb99ac18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Some animals use a liquid coming from their skin to adjust to (A) cold (B) water (C) heat (D) humidity',\n",
       " ['Sweat is a liquid produced by the skin that helps regulate body temperature.',\n",
       "  'Sweat helps animals regulate their body temperature in hot and humid environments.'])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 9\n",
    "df2.iloc[i][\"Complete Question\"], df2.iloc[i][\"Generated Premises\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "733a0a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the best way to guess a babies eye color? (A) The surroundings they are born in. (B) Their parents usual diet. (C) Just take a random guess. (D) The genealogy records of their family.',\n",
       " 'D')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: used chatgpt to help with prompt3b.txt -- worked pretty well\n",
    "\n",
    "i = 31\n",
    "df.iloc[i][\"Complete Question\"], df.iloc[i][\"Answer Key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "815509e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81949244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
