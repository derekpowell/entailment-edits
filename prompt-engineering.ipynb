{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6bdf34-8665-432b-a944-13ebe977aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/dmpowell/.cache/huggingface\n",
      "/scratch/dmpowell/.cache/huggingface/datasets\n",
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## set up configs for huggingface hub and OS paths on HPC cluster -- make sure config.ini is correct\n",
    "## ---------------------------------------------------------------------\n",
    "import configparser\n",
    "def auth_token():\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return config[\"hugging_face\"][\"token\"]\n",
    "\n",
    "def scratch_path():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return \"/scratch/\" + config[\"user\"][\"username\"] + \"/\"\n",
    "\n",
    "import os\n",
    "if os.path.isdir(scratch_path()):\n",
    "    os.environ['TRANSFORMERS_CACHE'] = scratch_path() + '.cache/huggingface'\n",
    "    os.environ['HF_DATASETS_CACHE'] = scratch_path() + '.cache/huggingface/datasets'\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n",
    "print(os.getenv('HF_DATASETS_CACHE'))\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Load libraries\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from entailma import * ## these are where the QA and prompting functions live now\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Ensure GPU is available -- device should == 'cuda'\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68833b8a-c4f5-48dd-8153-2c7ad99b7f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003053903579711914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ffcb777f474fcd96ad72ce57974e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## load llama-2 as a model (not pipeline, for reasons relating to other scripts)\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\" \n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = LlamaForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, device_map = \"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a29eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/obqa/test.tsv\", sep='\\t')\n",
    "df2 = df.copy().tail(10) # smaller df for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fde841-b59e-4675-95ca-bd83bc1367cc",
   "metadata": {},
   "source": [
    "## ~~answer_questions()~~ mc_choose_answer() function\n",
    "\n",
    "This function will read a multiple choice question from the dataset and output a single letter response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3f098e-cb23-49f8-9ee4-7ea3056e96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Model Answer'] = df2.apply(\n",
    "    lambda row: mc_choose_answer(row['Complete Question'], model, tokenizer),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4cc6000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df2[\"Answer Key\"] == df2[\"Model Answer\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72891a",
   "metadata": {},
   "source": [
    "This is getting ~58% accuracy. For reference, the original GPT-3 with 32-shot examples got 65.8% ([Brown et al., 2020](https://arxiv.org/abs/2005.14165v4)). So that seems not-too-bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e2e8c-053d-4f9a-8e1d-3f125b4dc5ac",
   "metadata": {},
   "source": [
    "## generate_premises() function\n",
    "~~This function will read the model's statement from the data set and provide two premises that would make the statement true.~~\n",
    "\n",
    "UPDATE: This seems to work better if we include the original question and answer, which eliminates a point of failure and gives more context for the explanation / premise generation.\n",
    "\n",
    "UPDATE 2: This is in the `entailma` library in this repo, but I've reproduced it here to make it easier to play around with as you/we tweak prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db215361-322c-42e9-a759-2ceb1c6d64c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "with open(\"entailma/prompt3b.txt\", 'r') as file:\n",
    "    premises_prompt = file.read()\n",
    "    \n",
    "\n",
    "def generate_premises(question, answer, model, tokenizer):\n",
    "    \n",
    "    input_str = f\"\\n\\n{premises_prompt}Question: {question}\\nAnswer: {answer}\\n\"\n",
    "\n",
    "    pipe = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        torch_dtype=torch.float16,\n",
    "        # device_map=\"cuda\",\n",
    "        device = model.device,\n",
    "        # use_auth_token = auth_token()\n",
    "    )\n",
    "\n",
    "    sequences = pipe(\n",
    "        input_str,\n",
    "        # do_sample=True,\n",
    "        # top_k = 50, \n",
    "        num_beams = 5, # beam search may be better ...\n",
    "        max_new_tokens=150,\n",
    "        temperature = 0.7\n",
    "    )\n",
    "    \n",
    "    generated_text = sequences[0]['generated_text']\n",
    "    premises = generated_text[len(input_str):-1] \n",
    "\n",
    "    return premises.split(\"\\n\")[:2]\n",
    "\n",
    "\n",
    "df2['Generated Premises'] = df2.apply(\n",
    "    lambda row: generate_premises(row['Complete Question'], row['Answer Key'], model, tokenizer),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59d76014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question Stem</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Complete Question</th>\n",
       "      <th>Answer Key</th>\n",
       "      <th>Model Answer</th>\n",
       "      <th>Generated Premises</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>9-743</td>\n",
       "      <td>where might a bunny live?</td>\n",
       "      <td>(A) a thicket (B) atop palm trees (C) a sewer ...</td>\n",
       "      <td>where might a bunny live? (A) a thicket (B) at...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>[Bunnies are small mammals that live in burrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>9-645</td>\n",
       "      <td>A shark will be unable to survive on eating al...</td>\n",
       "      <td>(A) it is a predator (B) it is a vegetarian (C...</td>\n",
       "      <td>A shark will be unable to survive on eating al...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>[Sharks are carnivorous predators that feed on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>8-250</td>\n",
       "      <td>A meadow vole just gave birth, and needs to fe...</td>\n",
       "      <td>(A) oil (B) deer (C) bugs (D) recycled plastic...</td>\n",
       "      <td>A meadow vole just gave birth, and needs to fe...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>[Meadow voles are herbivores, meaning they eat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>283</td>\n",
       "      <td>The Grand Canyon was formed by</td>\n",
       "      <td>(A) a volcano erupting in 1782 (B) a river nam...</td>\n",
       "      <td>The Grand Canyon was formed by (A) a volcano e...</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>[The Grand Canyon was formed by the Colorado R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>8-183</td>\n",
       "      <td>A woman, with a pale complexion, wants to spen...</td>\n",
       "      <td>(A) UV rays are harmful (B) sunlight will be f...</td>\n",
       "      <td>A woman, with a pale complexion, wants to spen...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>[Ultraviolet (UV) rays from the sun can cause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>9-284</td>\n",
       "      <td>A person is heating water in order to cook pas...</td>\n",
       "      <td>(A) scalds (B) cools (C) toasts (D) freezes</td>\n",
       "      <td>A person is heating water in order to cook pas...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>[Water boils at a temperature of 212°F (100°C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>7-1186</td>\n",
       "      <td>Pasta may be cooked in water when</td>\n",
       "      <td>(A) the water is warm (B) the water is on the ...</td>\n",
       "      <td>Pasta may be cooked in water when (A) the wate...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>[Water boils at a temperature of 212°F (100°C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>926</td>\n",
       "      <td>A decrease in diseases</td>\n",
       "      <td>(A) has no impact on a population (B) leads to...</td>\n",
       "      <td>A decrease in diseases (A) has no impact on a ...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>[A decrease in diseases leads to less sick peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7-519</td>\n",
       "      <td>When soil is viewed in a scientific way, what ...</td>\n",
       "      <td>(A) insects like big beetles (B) tiny lifeform...</td>\n",
       "      <td>When soil is viewed in a scientific way, what ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>[Soil is composed of mineral particles, organi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>7-7</td>\n",
       "      <td>Some animals use a liquid coming from their sk...</td>\n",
       "      <td>(A) cold (B) water (C) heat (D) humidity</td>\n",
       "      <td>Some animals use a liquid coming from their sk...</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>[Sweat is a liquid produced by the skin that h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                      Question Stem  \\\n",
       "490   9-743                          where might a bunny live?   \n",
       "491   9-645  A shark will be unable to survive on eating al...   \n",
       "492   8-250  A meadow vole just gave birth, and needs to fe...   \n",
       "493     283                     The Grand Canyon was formed by   \n",
       "494   8-183  A woman, with a pale complexion, wants to spen...   \n",
       "495   9-284  A person is heating water in order to cook pas...   \n",
       "496  7-1186                  Pasta may be cooked in water when   \n",
       "497     926                             A decrease in diseases   \n",
       "498   7-519  When soil is viewed in a scientific way, what ...   \n",
       "499     7-7  Some animals use a liquid coming from their sk...   \n",
       "\n",
       "                                               Choices  \\\n",
       "490  (A) a thicket (B) atop palm trees (C) a sewer ...   \n",
       "491  (A) it is a predator (B) it is a vegetarian (C...   \n",
       "492  (A) oil (B) deer (C) bugs (D) recycled plastic...   \n",
       "493  (A) a volcano erupting in 1782 (B) a river nam...   \n",
       "494  (A) UV rays are harmful (B) sunlight will be f...   \n",
       "495        (A) scalds (B) cools (C) toasts (D) freezes   \n",
       "496  (A) the water is warm (B) the water is on the ...   \n",
       "497  (A) has no impact on a population (B) leads to...   \n",
       "498  (A) insects like big beetles (B) tiny lifeform...   \n",
       "499           (A) cold (B) water (C) heat (D) humidity   \n",
       "\n",
       "                                     Complete Question Answer Key  \\\n",
       "490  where might a bunny live? (A) a thicket (B) at...          A   \n",
       "491  A shark will be unable to survive on eating al...          A   \n",
       "492  A meadow vole just gave birth, and needs to fe...          C   \n",
       "493  The Grand Canyon was formed by (A) a volcano e...          C   \n",
       "494  A woman, with a pale complexion, wants to spen...          A   \n",
       "495  A person is heating water in order to cook pas...          A   \n",
       "496  Pasta may be cooked in water when (A) the wate...          C   \n",
       "497  A decrease in diseases (A) has no impact on a ...          C   \n",
       "498  When soil is viewed in a scientific way, what ...          B   \n",
       "499  Some animals use a liquid coming from their sk...          C   \n",
       "\n",
       "    Model Answer                                 Generated Premises  \n",
       "490            A  [Bunnies are small mammals that live in burrow...  \n",
       "491            A  [Sharks are carnivorous predators that feed on...  \n",
       "492            C  [Meadow voles are herbivores, meaning they eat...  \n",
       "493            B  [The Grand Canyon was formed by the Colorado R...  \n",
       "494            A  [Ultraviolet (UV) rays from the sun can cause ...  \n",
       "495            A  [Water boils at a temperature of 212°F (100°C)...  \n",
       "496            A  [Water boils at a temperature of 212°F (100°C)...  \n",
       "497            C  [A decrease in diseases leads to less sick peo...  \n",
       "498            B  [Soil is composed of mineral particles, organi...  \n",
       "499            B  [Sweat is a liquid produced by the skin that h...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb6b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
