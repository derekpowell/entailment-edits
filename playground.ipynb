{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2724c7b6-3913-4e88-b25b-94e840895c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/dmpowell/.cache/huggingface\n",
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isdir('/scratch/dmpowell'):\n",
    "    os.environ['TRANSFORMERS_CACHE'] = '/scratch/dmpowell/.cache/huggingface'\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPTJForCausalLM, AutoTokenizer, AutoModel, GPT2LMHeadModel, AutoModelForCausalLM\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cdacaa0-6363-4cef-a960-7fda4a620bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\" # gpt2-xl / \"EleutherAI/gpt-j-6B\" / \"databricks/dolly-v1-6b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5646e18-fdf9-4b31-b49c-c7cc1ffe282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004677534103393555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 619,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139e052f23cd42c79f006372391d8dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0029158592224121094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 798156,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d729fd4460496993c3182aed57b7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0029299259185791016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 456356,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230ce84bc0054bb3a95f4ad6b2f2e4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0028498172760009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1373465,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f626529e07c7403eafa61dd0a61076a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003182649612426758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 4039,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6034f236a24d4390eb45b87ae91767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003182649612426758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 357,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38dc5ae8f264dd4973631583f2dd2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0031337738037109375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 930,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b21fafa0a54a429290bb9348dec5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0032639503479003906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 68,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 24207819307,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0c032823db43d7928b8c0b4996dcb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392974ac-8f06-4da0-9bbb-c5af70801a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(texts, model):\n",
    "    if type(texts) != list:\n",
    "        texts = [texts]\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    encoding = tokenizer(texts, padding=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**encoding, do_sample=False, max_new_tokens=300) # \n",
    "\n",
    "        generated_texts = tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "    return(generated_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca10d1a6-fa46-4ec9-a7a1-7ce3228528b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I was born and raised in the projects\n",
      "and my mother was a teenage mother\n",
      "I was a young boy living in the ghetto\n",
      "and my father was a young boy trying to make it\n",
      "I was a young boy with a dream\n",
      "and my sister was a young girl with a dream\n",
      "I was a young boy with a dream\n",
      "and my brother was a young boy with a dream\n",
      "I was a young boy with a dream\n",
      "and my sister was a young girl with a dream\n",
      "I was a young boy with a dream\n",
      "and my brother was a young boy with a dream\n",
      "I was a young boy with a dream\n",
      "and my sister was a young girl with a dream\n",
      "I was a young boy with a dream\n",
      "and my brother was a young boy with a dream\n",
      "I was a young boy with a dream\n",
      "and my sister was a young girl with a dream\n",
      "I was a young boy with a dream\n",
      "and my brother was a young boy with a dream\n",
      "I was a young boy with a dream\n",
      "and my sister was a young girl with a dream\n",
      "I was a young boy with a dream\n",
      "and my brother was a young boy with a dream\n",
      "I was a young boy with a dream\n",
      "and my sister was a young girl with a dream\n",
      "I was a young boy with a dream\n",
      "and my brother was a young boy with a dream\n",
      "I was a young boy with a dream\n",
      "and my sister was a young girl with a dream\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = ['The Fresh Prince of Bel Air theme song lyrics go:\\nThis is a story all about how\\nmy life got flipped turned upside down']\n",
    "\n",
    "for t in generate_text(texts, model): print(t[len(texts[0]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa164b0-e5a6-4f57-8129-5bc07b9e0c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
