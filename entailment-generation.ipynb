{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6bdf34-8665-432b-a944-13ebe977aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/dmpowell/.cache/huggingface\n",
      "/scratch/dmpowell/.cache/huggingface/datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmpowell/.conda/envs/EasyEdit/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/dmpowell/.conda/envs/EasyEdit/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## set up configs for huggingface hub and OS paths on HPC cluster -- make sure config.ini is correct\n",
    "## ---------------------------------------------------------------------\n",
    "import configparser\n",
    "def auth_token():\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return config[\"hugging_face\"][\"token\"]\n",
    "\n",
    "def scratch_path():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return \"/scratch/\" + config[\"user\"][\"username\"] + \"/\"\n",
    "\n",
    "import os\n",
    "if os.path.isdir(scratch_path()):\n",
    "    os.environ['TRANSFORMERS_CACHE'] = scratch_path() + '.cache/huggingface'\n",
    "    os.environ['HF_DATASETS_CACHE'] = scratch_path() + '.cache/huggingface/datasets' # update with latest HF\n",
    "\n",
    "os.environ['HF_TOKEN'] = auth_token()\n",
    "\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n",
    "print(os.getenv('HF_DATASETS_CACHE'))\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Load libraries\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from entailma import * ## these are where the QA and prompting functions live now\n",
    "from easyeditor.custom import EditedModel\n",
    "from easyeditor import LoRAHyperParams, FTHyperParams, BaseEditor\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Ensure GPU is available -- device should == 'cuda'\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68833b8a-c4f5-48dd-8153-2c7ad99b7f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/11/2024 17:58:54 - INFO - accelerate.utils.modeling -   We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0045588016510009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 73,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b6b00e68504c7e82a296f2b1c804c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## load llama-2 as a EditedModel class (not pipeline, to integrate better with other scripts/notebooks)\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\" # \"meta-llama/Meta-Llama-3-8B\" \n",
    "\n",
    "model = WrappedModel(\n",
    "    LlamaForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, device_map = \"auto\"),\n",
    "    LlamaTokenizer.from_pretrained(MODEL_NAME)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a29eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_stem</th>\n",
       "      <th>choices</th>\n",
       "      <th>complete_question</th>\n",
       "      <th>answer_key</th>\n",
       "      <th>foils</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>936</td>\n",
       "      <td>Animals died after the removal of a</td>\n",
       "      <td>(A) bush (B) street (C) house (D) city</td>\n",
       "      <td>Animals died after the removal of a (A) bush (...</td>\n",
       "      <td>A</td>\n",
       "      <td>[B, C, D]</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>8-478</td>\n",
       "      <td>If I want to go running at night, what can I u...</td>\n",
       "      <td>(A) A black shirt (B) Kitchen foil (C) Sunglas...</td>\n",
       "      <td>If I want to go running at night, what can I u...</td>\n",
       "      <td>B</td>\n",
       "      <td>[A, C, D]</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>9-669</td>\n",
       "      <td>the closest star to our planet delivers solar ...</td>\n",
       "      <td>(A) maybe (B) all of these (C) this is sure (D...</td>\n",
       "      <td>the closest star to our planet delivers solar ...</td>\n",
       "      <td>C</td>\n",
       "      <td>[A, B, D]</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>7-732</td>\n",
       "      <td>Coal-fire power stations heat coal to incredib...</td>\n",
       "      <td>(A) produce energy (B) use heat energy (C) bur...</td>\n",
       "      <td>Coal-fire power stations heat coal to incredib...</td>\n",
       "      <td>A</td>\n",
       "      <td>[B, C, D]</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>7-658</td>\n",
       "      <td>Creatures sometimes have barbs on their backs ...</td>\n",
       "      <td>(A) wasp (B) bee (C) scorpion (D) butterfly</td>\n",
       "      <td>Creatures sometimes have barbs on their backs ...</td>\n",
       "      <td>D</td>\n",
       "      <td>[A, B, C]</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                      question_stem  \\\n",
       "400    936                Animals died after the removal of a   \n",
       "401  8-478  If I want to go running at night, what can I u...   \n",
       "402  9-669  the closest star to our planet delivers solar ...   \n",
       "403  7-732  Coal-fire power stations heat coal to incredib...   \n",
       "404  7-658  Creatures sometimes have barbs on their backs ...   \n",
       "\n",
       "                                               choices  \\\n",
       "400             (A) bush (B) street (C) house (D) city   \n",
       "401  (A) A black shirt (B) Kitchen foil (C) Sunglas...   \n",
       "402  (A) maybe (B) all of these (C) this is sure (D...   \n",
       "403  (A) produce energy (B) use heat energy (C) bur...   \n",
       "404        (A) wasp (B) bee (C) scorpion (D) butterfly   \n",
       "\n",
       "                                     complete_question answer_key      foils  \\\n",
       "400  Animals died after the removal of a (A) bush (...          A  [B, C, D]   \n",
       "401  If I want to go running at night, what can I u...          B  [A, C, D]   \n",
       "402  the closest star to our planet delivers solar ...          C  [A, B, D]   \n",
       "403  Coal-fire power stations heat coal to incredib...          A  [B, C, D]   \n",
       "404  Creatures sometimes have barbs on their backs ...          D  [A, B, C]   \n",
       "\n",
       "    F1 F2 F3  \n",
       "400  B  C  D  \n",
       "401  A  C  D  \n",
       "402  A  B  D  \n",
       "403  B  C  D  \n",
       "404  A  B  C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/obqa/test.tsv\", sep='\\t')\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df2 = df.copy().tail(100)\n",
    "\n",
    "df2 = (\n",
    "    df2\n",
    "    .assign(foils = lambda d: d.apply(lambda x: [i for i in [\"A\",\"B\",\"C\",\"D\"] if i != x[\"answer_key\"]], 1))\n",
    "    .assign(\n",
    "        F1 = lambda d: d.apply(lambda x: x.foils[0], 1),\n",
    "        F2 = lambda d: d.apply(lambda x: x.foils[1], 1),\n",
    "        F3 = lambda d: d.apply(lambda x: x.foils[2], 1)\n",
    "        )\n",
    ")\n",
    "\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db215361-322c-42e9-a759-2ceb1c6d64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lil test\n",
    "# row = df2.iloc[-1]\n",
    "# out = generate_best_premises(row.complete_question, 'A', model, num_prem = 8, batch_size = 8)\n",
    "# print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a9356a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0030133724212646484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 73,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605ce53e6c5a40b6979b2556f82b3d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorr_premises\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m corr_premises\n\u001b[1;32m     25\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1_premises\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m foil_premises\n\u001b[0;32m---> 26\u001b[0m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorr_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m corr_scores\n\u001b[1;32m     27\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m foil_scores\n\u001b[1;32m     29\u001b[0m df2\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest-tail100-premises-bestof32.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/EasyEdit/lib/python3.9/site-packages/pandas/core/frame.py:3656\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3655\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3656\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/EasyEdit/lib/python3.9/site-packages/pandas/core/frame.py:3833\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3824\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3826\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3832\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3833\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3835\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3836\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3838\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3839\u001b[0m     ):\n\u001b[1;32m   3840\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3841\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.conda/envs/EasyEdit/lib/python3.9/site-packages/pandas/core/frame.py:4538\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4537\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 4538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/EasyEdit/lib/python3.9/site-packages/pandas/core/construction.py:593\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    591\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _try_cast(data, dtype, copy, raise_cast_failure)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 593\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subarr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    595\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m~/.conda/envs/EasyEdit/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:122\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    119\u001b[0m arr: ArrayLike\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mrange\u001b[39m)):\n\u001b[0;32m--> 122\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_1d_object_array_from_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# The caller is responsible for ensuring that we have np.ndarray\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m#  or ExtensionArray here.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     arr \u001b[38;5;241m=\u001b[39m values\n",
      "File \u001b[0;32m~/.conda/envs/EasyEdit/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1981\u001b[0m, in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;66;03m# numpy will try to interpret nested lists as further dimensions, hence\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;66;03m# making a 1D array that contains list-likes is a bit tricky:\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(values), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1981\u001b[0m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/EasyEdit/lib/python3.9/site-packages/torch/_tensor.py:972\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "corr_premises = []\n",
    "foil_premises = []\n",
    "\n",
    "corr_scores = []\n",
    "F1_scores = []\n",
    "\n",
    "for row in tqdm(df2.itertuples(), total = len(df2)):\n",
    "    try:\n",
    "        corr, corr_score = generate_best_premises(row.complete_question, row.answer_key, model, num_prem = 32, batch_size = 8)\n",
    "    except:\n",
    "        corr, corr_score = [\"\", \"\"], -100\n",
    "    try:\n",
    "        F1, F1_score = generate_best_premises(row.complete_question, row.F1, model, num_prem = 32, batch_size = 8)\n",
    "    except:\n",
    "        F1, F1_score = [\"\", \"\"], -100\n",
    "\n",
    "    corr_premises.append(corr)\n",
    "    foil_premises.append(F1)\n",
    "    corr_scores.append(corr_score)\n",
    "    F1_scores.append(F1_score)\n",
    "\n",
    "df2['corr_premises'] = corr_premises\n",
    "df2['F1_premises'] = foil_premises\n",
    "df2['corr_score'] = [x.cpu().item() if type(x)==torch.Tensor else x for x in corr_scores]\n",
    "df2['F1_score'] = [x.cpu().item() if type(x)==torch.Tensor else x for x in F1_scores]\n",
    "\n",
    "df2.to_csv('test-tail100-premises-bestof32.csv', sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df1d692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for row in df2.itertuples():\n",
    "#     corr_premises = generate_best_premises(row.complete_question, row.answer_key, model, num_prem = 32, batch_size = 8)\n",
    "#     F1_premises = generate_best_premises(row.complete_question, row.F1, model, num_prem = 32, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c689f354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.599609375,\n",
       " 10.0859375,\n",
       " 0.736328125,\n",
       " 1.373046875,\n",
       " 0.9287109375,\n",
       " 3.44921875,\n",
       " 11.0703125,\n",
       " 1.1884765625,\n",
       " 0.9111328125,\n",
       " 1.916015625,\n",
       " 6.546875,\n",
       " 2.73046875,\n",
       " 13.703125,\n",
       " -100.0,\n",
       " 8.0,\n",
       " 1.2265625,\n",
       " 3.810546875,\n",
       " 2.97265625,\n",
       " 5.93359375,\n",
       " 16.796875,\n",
       " 7.05078125,\n",
       " 23.421875,\n",
       " 3.220703125,\n",
       " 1.9189453125,\n",
       " 3.84375,\n",
       " 5.125,\n",
       " 7.3671875,\n",
       " 16.0625,\n",
       " 5.53125,\n",
       " 7.53125,\n",
       " 3.365234375,\n",
       " 2.1328125,\n",
       " 6.8359375,\n",
       " 2.244140625,\n",
       " 8.234375,\n",
       " 24.265625,\n",
       " 3.697265625,\n",
       " 1.61328125,\n",
       " 7.00390625,\n",
       " 2.0390625,\n",
       " 1.802734375,\n",
       " 2.0,\n",
       " 3.841796875,\n",
       " 0.83984375,\n",
       " 2.017578125,\n",
       " 1.5244140625,\n",
       " 3.513671875,\n",
       " 2.7734375,\n",
       " 5.4375,\n",
       " -100.0,\n",
       " 3.94140625,\n",
       " 5.05078125,\n",
       " 5.40625,\n",
       " 4.5,\n",
       " 2.755859375,\n",
       " 0.65771484375,\n",
       " 2.611328125,\n",
       " 3.607421875,\n",
       " 9.140625,\n",
       " 4.87890625,\n",
       " 2.12890625,\n",
       " 1.259765625,\n",
       " 1.953125,\n",
       " 3.939453125,\n",
       " 6.09765625,\n",
       " 2.36328125,\n",
       " 3.830078125,\n",
       " 1.7060546875,\n",
       " 2.744140625,\n",
       " 2.49609375,\n",
       " 1.69140625,\n",
       " 5.30078125,\n",
       " 4.58203125,\n",
       " 3.029296875,\n",
       " 2.294921875,\n",
       " 0.64208984375,\n",
       " 5.46875,\n",
       " 20.90625,\n",
       " 10.140625,\n",
       " 3.3125,\n",
       " 2.509765625,\n",
       " 3.08984375,\n",
       " 1.39453125,\n",
       " 1.9775390625,\n",
       " 3.9609375,\n",
       " 2.54296875,\n",
       " 5.69140625,\n",
       " 4.96875,\n",
       " 7.96484375,\n",
       " 0.78759765625,\n",
       " 4.7578125,\n",
       " 2.34765625,\n",
       " 8.234375,\n",
       " -100.0,\n",
       " 2.013671875,\n",
       " 2.38671875,\n",
       " 2.138671875,\n",
       " 5.87890625,\n",
       " 3.47265625,\n",
       " 1.810546875]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.cpu().item() if type(x)==torch.Tensor else x for x in corr_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46c63ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I don't think this is very useful for evaluating \"belief\"\n",
    "# def text_logprob(text, model, norm = None):\n",
    "#     if not norm:\n",
    "#         norm = 1\n",
    "#     elif norm == \"whitespace\":\n",
    "#         norm = len(text.split())\n",
    "    \n",
    "#     logprobs = model.obs_logprobs(text)\n",
    "#     return [l.sum()/norm for l in logprobs] if type(logprobs)==list else logprobs.sum()/norm\n",
    "    \n",
    "# [text_logprob(t, model, norm = \"whitespace\") for t in ['Some animals sweat in the heat to keep cool.', 'Sweat is a liquid that evaporates from the skin, which cools the body.']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "easyedit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
